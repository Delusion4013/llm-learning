{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1376709",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "Normalization is a common strategy to map values with different ranges (distributions) to the same range.\n",
    "\n",
    "Normalization in deep learning could:\n",
    "- mitigates vanishing gradient\n",
    "- speed up model convergence \n",
    "- boost generalization\n",
    "\n",
    "Based on different scenarios and network architecture, there are multiple normalization techniques:\n",
    "1. Batch Norm\n",
    "2. Layer Norm\n",
    "3. Instance Norm\n",
    "4. Group Norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e011448a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab75709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f052782",
   "metadata": {},
   "source": [
    "### Batch Norm (BN)\n",
    "\n",
    "**Intuition**: Compute the mean and variance for each channel along the batch dimension before activation functions, and normalize the activation values to a distribution with mean 0 and variance 1 (plus learnable scaling and bias parameters).\n",
    "\n",
    "**Background**: when performing gradient descent on mini-batches, the distribution of each batch is different, causing the input distribution of each network layer to continuously shift during training (*Internal Covariate Shift*, ICS). This makes model training difficult, slows down convergence, and can even lead to Vanishing Gradient or Exploding gradient problems.\n",
    "\n",
    "BN **Effect**:\n",
    "- Mitigate internal covariate shift, prevent Vanishing Gradient / Exploding gradient\n",
    "- Allow using big Learning rate\n",
    "- Reduce the sensitivity to weight initialization\n",
    "- A minor Regularization effect on hidden layer's output\n",
    "\n",
    "Potential **problems**:\n",
    "- When *batch size small*: the mean / variance is not accurate to represent the entire data distribution\n",
    "- When *batch size big*: memory cost ↑\n",
    "- Not suitable for *variable length situation* (like sequence input)\n",
    "\n",
    "![batch-norm-illustration](../assets/imgs/batch-norm-illustration.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac11875",
   "metadata": {},
   "source": [
    "#### Calculation\n",
    "\n",
    "Assuming the output dimension of a layer is `[B, C, H, W]`, where `B` represents batch size, `C` represents number of channels, and `H` and `W` represent the height and width of the feature map respectively. We compute the mean and variance for each batch along the channel dimension, i.e., performing statistics on all sample pixels within the same channel:\n",
    "\n",
    "1. **Calculate mean** $\\mu_c$: $$\\mu_c = \\frac{1}{B \\times H \\times W} \\sum_{b=1}^{B} \\sum_{h=1}^{H} \\sum_{w=1}^{W} x_{b,c,h,w}$$\n",
    "2. **Calculate variance** $\\sigma_c^2$: $$\\sigma_c^2 = \\frac{1}{B \\times H \\times W} \\sum_{b=1}^{B} \\sum_{h=1}^{H} \\sum_{w=1}^{W} (x_{b,c,h,w} - \\mu_c)^2$$\n",
    "3. **Normalization**: $$\\hat{x}_{b,c,h,w} = \\frac{x_{b,c,h,w} - \\mu_c}{\\sqrt{\\sigma_c^2 + \\epsilon}}$$\n",
    "4. **Scale and shift**: $$y_{b,c,h,w} = \\gamma_c \\hat{x}_{b,c,h,w} + \\beta_c$$\n",
    "Where $\\gamma_c$ and $\\beta_c$ are learnable parameters (initially set to $\\gamma_c = 1, \\beta_c = 0$).\n",
    "\n",
    "Since it's usually image input that uses Batch normalization, I chose `BatchNorm2d` here for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b648a033",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_features, height, weight = 20, 100, 35, 45\n",
    "test_input = torch.randn(batch_size, num_features, height, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c55d456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch calculation\n",
    "# Without Learnable Parameters\n",
    "m = nn.BatchNorm2d(num_features, affine=False)\n",
    "torch_output = m(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69820db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual calculation\n",
    "eps = 1e-5 # defualt\n",
    "mu_c = test_input.mean(dim=(0,2,3), keepdim=True) # Over Batch, hw dimensions\n",
    "var_c = test_input.var(dim=(0,2,3), keepdim=True, unbiased=False) # Use population variance\n",
    "manual_output = (test_input - mu_c) / torch.sqrt(var_c + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f04c7412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(torch_output, manual_output, atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a86864f",
   "metadata": {},
   "source": [
    "### Layer Norm (LN)\n",
    "\n",
    "For sequence based tasks, batch size could be very small (even to 1), and the input length varies, so Batch Normalization do not work so well. **Layer Norm** is proposed to normalize over a single instance's feature.\n",
    "\n",
    "The mean and standard-deviation are calculated over the last D dimensions, where D is the dimension of `normalized_shape`. For example, if `normalized_shape` is `(3, 5)` (a 2-dimensional shape), the mean and standard-deviation are computed over the last 2 dimensions of the input (i.e. `input.mean((-2, -1))`).\n",
    "\n",
    "![layer-norm-illustration](../assets/imgs/layer-norm-illustration.png)\n",
    "\n",
    "$$\\mathbf{y} = \\frac{\\mathbf{x} - \\text{E}(\\mathbf{x})}{\\sqrt{\\text{Var}(\\mathbf{x}) + \\varepsilon}} * \\gamma + \\beta$$\n",
    "\n",
    "Characteristics of LN:\n",
    "- **Not dependent on Batch**\n",
    "- Good performance on sequence models (Recurrent Neural Network, Transformer): as it's irrelevant to batch size and sequence length\n",
    "- Not as good as batch normalization on CNN: as each channel is included in calculation, some local features may be lost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ef6670",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aee36ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP Example\n",
    "batch, seq_len, embedding_dim = 4, 5, 10\n",
    "embedding = torch.randn(batch, seq_len, embedding_dim)\n",
    "layer_norm = nn.LayerNorm(embedding_dim)\n",
    "# Activate module\n",
    "torch_output = layer_norm(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cf2c423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Layer Normalization\n",
    "eps = 1e-5\n",
    "# Compute mean and variance across the last dimension (embedding_dim)\n",
    "mu = embedding.mean(dim=-1, keepdim=True)  # Shape: (4, 5, 1)\n",
    "var = embedding.var(dim=-1, keepdim=True, unbiased=False)  # Shape: (4, 5, 1)\n",
    "manual_output = (embedding - mu) / torch.sqrt(var + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4890ef36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(torch_output, manual_output, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a56e5b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Example\n",
    "B, C, H, W = 20, 5, 10, 10\n",
    "test_input = torch.randn(B, C, H, W)\n",
    "# Normalize over the last three dimensions (i.e. the channel and spatial dimensions)\n",
    "layer_norm = nn.LayerNorm([C, H, W], elementwise_affine=False) # Remove learnable params\n",
    "torch_output = layer_norm(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d8ce77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Layer Normalization\n",
    "eps = 1e-5\n",
    "mu = test_input.mean(dim=(1,2,3), keepdim=True)   # Shape: (B, 1, 1, 1), over channel,HW dimensions\n",
    "var = test_input.var(dim=(1,2,3), keepdim=True, unbiased=False)  \n",
    "manual_output = (test_input - mu) / torch.sqrt(var + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00e85482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(torch_output, manual_output, atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049dd77f",
   "metadata": {},
   "source": [
    "### Instance Norm\n",
    "\n",
    "Instance normalization are proposed in *image style transfer* task - [paper](https://arxiv.org/abs/1607.08022).\n",
    "\n",
    "In style transfer networks, each image's style is often only affected by that single image's feature distribution. Batch Normalization's \"cross-sample\" normalization cannot preserve the style differences of individual images. Therefore, normalization needs to be **performed separately on each image's feature map**, operating on the H×W dimensions while preserving the batch and channel dimensions.\n",
    "\n",
    "![instance_norm](../assets/imgs/instance-norm-illustration.png)\n",
    "\n",
    "$$\\begin{align*}\n",
    "μ_{n,c} &= \\frac{1}{HW}∑_{h=1}^H ∑_{w=1}^W x_{n,c,h,w}\\\\\n",
    "\n",
    "\\sigma^2_{n,c} &= \\frac{1}{HW} ∑_{h=1}^H ∑_{w=1}^W (x_{n,c,h,w} - \\mu_{n,c})^2\\\\\n",
    "\n",
    "y_{n,c,h,w} &= (x_{n,c,h,w} - μ_{n,c})/\\sqrt{(\\sigma^2_{n,c} + ε)}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Characteristics of IN:\n",
    "- Normalization over each sample and channel, presevered inter-sample and inter-channel features\n",
    "- Good for style transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4205d017",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_features, height, weight = 20, 100, 35, 45\n",
    "test_input = torch.randn(batch_size, num_features, height, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8030c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch calculation\n",
    "# Without Learnable Parameters\n",
    "m = nn.InstanceNorm2d(num_features, affine=False)\n",
    "torch_output = m(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06a0316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual calculation\n",
    "eps = 1e-5 # defualt\n",
    "mu_c = test_input.mean(dim=(2,3), keepdim=True) # Over HW dimensions\n",
    "var_c = test_input.var(dim=(2,3), keepdim=True, unbiased=False) # Use population variance\n",
    "manual_output = (test_input - mu_c) / torch.sqrt(var_c + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5828ab30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(torch_output,manual_output,atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80c3e28",
   "metadata": {},
   "source": [
    "### Group Norm\n",
    "\n",
    "Group normalization are proposed to cater for the dependence of Batch Normalization on the *batch size*. When the batch size is small, BN's estimated mean and variance become biased. \n",
    "\n",
    "GN proposed to **group channels** then perform Layer-norm like norm within each group.\n",
    "\n",
    "![group-norm-illustration.png](../assets/imgs/group-norm-illustration.png)\n",
    "\n",
    "\n",
    "$$\\mu_{n,g} = \\frac{1}{(C/G) H W} \\sum_{c=g\\frac{C}{G}}^{(g+1)\\frac{C}{G}-1} \\sum_{h=1}^{H} \\sum_{w=1}^{W} x_{n,c,h,w}$$\n",
    "\n",
    "$$\\sigma_{n,g} = \\sqrt{\\frac{1}{(C/G) H W} \\sum_{c=g\\frac{C}{G}}^{(g+1)\\frac{C}{G}-1} \\sum_{h=1}^{H} \\sum_{w=1}^{W} (x_{n,c,h,w} - \\mu_{n,g})^2 + \\varepsilon}$$\n",
    "\n",
    "\n",
    "\n",
    "Focus more on channel structure than Layer Norm, but not rely too much on batch size like Batch Norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d77ea413",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_features, height, weight = 20, 100, 35, 45\n",
    "test_input = torch.randn(batch_size, num_features, height, weight)\n",
    "num_groups = 4\n",
    "m = nn.GroupNorm(num_groups,num_features,affine=False)\n",
    "torch_output = m(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d51abf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-5 # defualt\n",
    "assert num_features % num_groups == 0, f\"Channels {num_features} must be divisible by num_groups {num_groups}\"\n",
    "channel_per_group = num_features // num_groups\n",
    "\n",
    "# einops in-replace of torch.view\n",
    "test_input_grouped = rearrange(test_input, 'b (ng gc) h w -> b ng gc h w', ng=num_groups)\n",
    "\n",
    "mu_c = test_input_grouped.mean(dim=(2,3,4), keepdim=True) # Over HW dimensions\n",
    "var_c = test_input_grouped.var(dim=(2,3,4), keepdim=True, unbiased=False) # Use population variance\n",
    "normalized_output = (test_input_grouped - mu_c) / torch.sqrt(var_c + eps)\n",
    "manual_output = rearrange(normalized_output, 'b ng gc h w -> b (ng gc) h w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82d447c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(torch_output, manual_output, atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d8d812",
   "metadata": {},
   "source": [
    "### RMS Norm\n",
    "\n",
    "RMS Norm (Root Mean Square Layer Normalization) is an improvement over Layer Norm: it **removes the dependence on the mean** and only depends on the variance of the vector. In some large models (such as certain large language models), RMS Norm has been *proven to reduce training instability and achieve better or faster convergence*.\n",
    "\n",
    "$$\n",
    "\\text{RMS}(\\mathbf{a}) = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n a_i^2}\n",
    "$$\n",
    "\n",
    "- **Advantages**: Removes mean operations, reduces computation; provides better stability in some situations.\n",
    "- **Disadvantages**: Compared to LN, RMS Norm lacks the \"centering\" process, which may impact feature distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd2c9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_features, height, weight = 20, 100, 35, 45\n",
    "test_input = torch.randn(batch_size, num_features, height, weight)\n",
    "m = nn.RMSNorm([num_features,height,weight], elementwise_affine=False)\n",
    "torch_output = m(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "488ad465",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-5 # defualt\n",
    "mu_c = torch.mean(test_input**2, dim=(1,2,3), keepdim=True)\n",
    "manual_output = test_input / torch.sqrt(mu_c + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "305db9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(torch_output, manual_output, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203a0915",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
